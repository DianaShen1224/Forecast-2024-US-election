---
title: "Forecasting 2024 US election using linear regression"
author: 
  - Diana Shen
  - Jinyan Wei
  - Jerry Yu
thanks: "Code and data are available at: [https://github.com/DianaShen1224/Forecast-2024-US-election](https://github.com/DianaShen1224/Forecast-2024-US-election)."
date: today
date-format: long
abstract: "
This paper predicts the outcome of the 2024 U.S. presidential election using a statistical model based on aggregated polling data for Kamala Harris and Donald Trump. We employ multi-level regression with post-stratification (MRP) using demographic predictors to estimate voter support. The analysis addresses polling biases and proposes an idealized survey methodology with a $100,000 budget. Our results offer insights into voter behavior and suggest improvements for future election forecasting models."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```


# Introduction

Election forecasting has long played a crucial role in understanding public opinion and predicting the outcome of political contests. The use of data-driven methods, particularly polling data, has become an important pre-election analytical tool for political analysts. The purpose of this paper is to predict the winner of the upcoming 2024 U.S. presidential election by constructing a statistical model based on aggregated polling data. The “polling” approach combines results from different pollsters to provide a more comprehensive picture of voter preferences (Blumenthal 2014; Pasek 2015), and our goal is to predict the outcome of the popular vote and the Electoral College. Our analysis, based on data collected from multiple polling sources, captures voter intentions for the two major candidates, Kamala Harris (Democrat) and Donald Trump (Republican).

In addition to constructing and interpreting predictive models, this paper dive into the methods used by xx pollsters, analyzing the strengths as well as the weaknesses of the methods used against them. At the end of the paper, we also propose an idealized survey methodology for election forecasting with a budget of $100,000 USD.

This paper begins with an introduction to data in Section 2. In this section, we focus on measurement techniques and the visualization and analysis of key variables. Next, in Section 3, we provide an overview of the linear model used to analyze the relationships within the dataset. The results of the analysis are detailed in Section 4 (Results). Finally, in Section 5, we summarize our main conclusions as well as suggest some possible future research directions.






# Data {#sec-data}

## Overview

The data for this paper was sourced from ABC News (xxxxx). The statistical software R (R Core Team, 2023) was employed to retrieve, clean, and process the dataset. Specifically, the tidyverse package (Wickham et al., 2019) was used for data acquisition, cleaning, and processing. The ggplot2 (Wickham, 2016) package was utilized to generate the visualizations.

## Measurement
	
The data used to predict the outcome of the 2024 U.S. presidential election in this study came from a variety of polling sources. The results of these polls represent key measures of electoral support and voter sentiment, and are therefore the main variables in our analysis.

To ensure that polling data accurately reflect real-world voter preferences, we rely on several key measurement constructs. First, voter preferences are measured by the percentage of respondents who indicated support for each candidate. Each poll is conducted using different sample sizes, sampling methods (e.g., online surveys, IVR calls, etc.), which can inject more variability into the data. To mitigate these differences, we aggregate poll results using a “”poll of polls“” methodology that eliminates anomalies and provides a more comprehensive picture of voter preferences (Blumenthal 2014; Pasek 2015).

In this study, we recognize the measurement problems inherent in polling data. Polls rely on sample data to represent the entire voting population, and therefore, there may be potential biases in the data. For example, there may be no-response bias due to the potential under representation of certain populations, or because of the wording of the questions and thus the influence of respondents to report their preferences. Therefore, in this study, we chose to analyze aggregated data from multiple pollsters and adjust for sampling variability and response rates in an effort to be able to provide a more robust measure of electoral support. We believe that our aggregated dataset can serve as a reliable basis for our predictive model to help us translate the data into quantitative metrics that can be used to predict election outcomes.


## Outcome variables


## Predictor variables

# Model

We performed multi-level regression with post-stratification (MRP) to predict support for Kamala Harris in the upcoming election. To perform MRP, we fit a logistic regression model to predict support for Harris using sex, age, race, race_hispanic, highest level of education, state, and urban as predictors on our survey data set [@americaspoliticalpulse], and post-stratified it using ACS census data [@citeIPUMS].

## Model set-up

We built our Bayesian logistic regression model using the `stan_glm()` function of the `rstanarm` package [@rstanarm]. The model that we use is:

\begin{align} 
vote\_harris_i|\pi_i &\sim \text{Bernoulli}(\pi_i) \\
\text{logit}(\pi_i) &= \beta_0 + \beta_1 \text{sex}_i + \beta_2  \text{age\_bracket}_i + \beta_3 \text{race}_i + \beta_4 \text{race\_hispanic}_i + \beta_5 \text{education\_level}_i + \beta_6 \text{urban}_i \\
\beta_0 &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5) \\
\beta_4 &\sim \text{Normal}(0, 2.5) \\
\beta_5 &\sim \text{Normal}(0, 2.5) \\
\beta_6 &\sim \text{Normal}(0, 2.5)
\end{align}

where binary variable $vote\_harris_i$ is equal to 1 if the respondent's preferred 2024 presidential candidate is Kamala Harris, or 0 if the respondent's preferred 2024 presidential candidate is Donald Trump. We run our model in R [@citeR] using `stan_glm`, with the default priors from `rstanarm` [@citerstanarm]. We then apply our model to our post-stratification data [@citeIPUMS] to predict the popular vote and electoral college results of the 2024 U.S. Presidential election.

Our model uses logistic regression, therefore one of its weaknesses is the fact that it predicts a binary outcome and does not consider the possibility that some American adults might vote for a third-party candidate or abstain from voting. Tradeoffs and concerns about our model are discussed in more detail in @sec-weaknesses-limitations.

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between certain demographic characteristics and support for Kamala Harris. Specifically:

- **Sex**: We might expect differences in support between male and female respondents, with women potentially being more likely to support Kamala Harris due to certain policy stances that may appeal to this demographic.
- **Age Bracket**: Age can be a significant factor, as younger voters might lean more progressive, potentially increasing support for Kamala Harris compared to Donald Trump.
- **Race and Hispanic Ethnicity**: Historical voting patterns suggest that non-white racial groups, including Hispanic voters, may show stronger support for Democratic candidates, such as Harris. This is reflected in the coefficients $\beta_3$ for race and $\beta_4$ for Hispanic ethnicity.
- **Education Level**: Higher education levels are often correlated with progressive political views, so we might expect a positive relationship between education level and support for Harris.
- **Urban**: Respondents living in urban areas may be more likely to support Kamala Harris due to the urban-rural political divide observed in recent elections, where urban areas tend to lean more Democratic.

The coefficients, such as $\beta_1$ for sex and $\beta_2$ for age bracket, represent the strength of these relationships. For example, a positive value of $\beta_1$ would suggest that being female increases the probability of supporting Harris, all else being equal.

By using normal priors like $\beta_1 \sim \text{Normal}(0, 2.5)$, we assume that, before seeing the data, the effect of each predictor on the log-odds of supporting Kamala Harris is centered around zero, but with flexibility for the data to inform the posterior estimates.

The Bayesian framework allows us to capture the uncertainty in our estimates and to refine our understanding of how different factors influence political support as new data becomes available. This is especially important in political forecasting, where the relationships between demographic factors and candidate support can be influenced by evolving social and political dynamics.



# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```





# Discussion

## First discussion point {#sec-first-point}


## Second discussion point



## Third discussion point

## Weaknesses and next steps



\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```


# Appendix
## Emerson College Polling Methodology
For this deep dive, I'll focus on Emerson College Polling based on the link: Emerson College Polling - October 2024 National Poll.
Survey Overview:
The Emerson College Polling conducted a national survey in October 2024 to assess voter preferences for the upcoming U.S. presidential election. This appendix provides an in-depth analysis of their polling methodology, including the population, sample frame, recruitment process, and key strengths and weaknesses of their approach.

Methodology
1. Population, Frame, and Sample:\
Target Population: The target population for this poll includes U.S. citizens who are eligible to vote in the 2024 presidential election.
Sample Frame: The sample consists of likely voters across the United States. Emerson College Polling uses voter registration databases to develop a sampling frame of registered voters, ensuring they capture individuals who are most likely to vote in the upcoming election.
Sample Size: For this particular poll, 1,000 likely voters were surveyed. This sample size provides a margin of error of approximately ±3 percentage points, allowing for reasonable confidence in the poll's accuracy.

2. Sample Recruitment:\
Recruitment Method: Emerson College employs a multi-mode recruitment approach, including online, phone (landline and mobile), and SMS text outreach.
Phone Interviews: Live interviewers call both landlines and mobile phones using random digit dialing (RDD) to ensure they capture respondents without internet access.
Online Panels: Emerson also recruits respondents through online panels, using email invitations to individuals who match their demographic quotas.
SMS Text Polling: In recent years, Emerson has increasingly used SMS text polling, allowing respondents to complete the survey via mobile devices.

Trade-offs of Recruitment Method:\
Strengths: The multi-mode approach ensures better coverage of different demographic groups, including older adults and those less likely to engage with online surveys.
Weaknesses: The RDD approach can lead to lower response rates, especially with the increasing number of people avoiding unsolicited calls. The online component also introduces self-selection bias, where more politically engaged individuals may be overrepresented.

3. Sampling Approach and Trade-offs:\
Quota-based Sampling: Emerson uses quota sampling to ensure that the sample is representative of key demographics, including age, gender, race, and region. The quotas are based on U.S. Census data to maintain demographic diversity.
Weighting: After data collection, Emerson applies post-stratification weighting to adjust for any imbalances in the sample, aligning it with population benchmarks.
Trade-offs: While quota sampling ensures demographic diversity, it can introduce bias if certain groups are harder to reach or more likely to refuse participation (non-response bias). Weighting helps mitigate this issue but relies on accurate population benchmarks, which may not always reflect the electorate’s behavior accurately.

4. Non-response Handling:\
Non-response Bias: To minimize non-response bias, Emerson College Polling uses a combination of call-backs and reminder emails for online respondents. Additionally, post-survey weighting accounts for non-response patterns across key demographic groups.
Adjustments for Non-response: Emerson uses statistical weighting to adjust the final results based on the response rate within each demographic group (e.g., age, gender, and race). This helps to reduce the skew in the data caused by differential response rates.

5. Questionnaire Design:\
Strengths:
The survey is concise, focusing on core topics like voter intention, candidate preference, and key issues such as the economy and healthcare. This increases the likelihood that respondents complete the survey accurately and without fatigue.
Emerson regularly tests its questionnaire to ensure clarity and avoid ambiguous questions, improving the reliability of the responses.
Weaknesses:
Binary Choice Bias: Some sections of the questionnaire force a binary choice between two candidates, which may oversimplify the respondents' true preferences, especially in a race with multiple candidates or undecided voters.
Social Desirability Bias: Like most political polls, respondents may answer questions in a way they believe is socially acceptable, especially in terms of voter turnout or support for controversial candidates. This could lead to over-reporting of voter intention.
Summary of Strengths and Weaknesses
Strengths:

Multi-mode Surveying: Emerson’s use of phone, online, and SMS recruitment allows them to reach a broader cross-section of the population, minimizing the biases introduced by any one method.
Post-stratification Weighting: The weighting process ensures the sample reflects the U.S. population, improving the reliability of the poll results.
Timely Polling: The frequent release of polling data makes it possible to track shifts in voter sentiment over time.
Weaknesses:

Potential for Non-response Bias: Despite efforts to mitigate it, non-response remains a concern, particularly among certain voter demographics who may be harder to reach through phone or online surveys.
Self-selection Bias in Online Surveys: The online component may disproportionately attract respondents who are more politically engaged, which could skew results.
By employing a multi-mode approach and adjusting for demographic imbalances through weighting, Emerson College Polling provides robust and timely data. However, like all polls, it is subject to limitations, particularly around non-response and self-selection biases​

## Idealized Methodology for US Presidential Election Forecast
This appendix outlines the methodology and design for conducting a U.S. presidential election forecast survey with a budget of $100,000. The goal is to develop an accurate and reliable prediction of the election outcome, ensuring data quality through careful sampling, recruitment, validation, and aggregation of results.

Methodology Overview
1. Sampling Approach
To ensure a representative sample of likely voters, I will use a stratified random sampling method based on demographic and voter turnout data from the U.S. Census and previous elections.

Target Population: U.S. citizens eligible to vote in the 2024 U.S. presidential election.
Sample Size: I plan to survey 3,500 respondents, providing a margin of error of approximately ±1.7 percentage points, ensuring a high level of confidence in the results.
Stratification Variables: The sample will be stratified by age, gender, race/ethnicity, education level, geographic region, and income. This ensures that each demographic group is represented proportionally to the U.S. population.
Oversampling: To ensure insights into underrepresented or low-response groups (e.g., younger voters, minorities), I will oversample these groups and apply appropriate post-stratification weighting.
2. Recruitment of Respondents
I will use a multi-modal approach to recruit a diverse and representative sample, employing both online and offline strategies to reach various segments of the population.

Online Recruitment: Use targeted advertisements on social media platforms (e.g., Facebook, Instagram) and popular news websites. A portion of the budget will be allocated to recruiting via established online panel providers such as Qualtrics or YouGov.
Phone and SMS Polling: To capture voters who may not engage online, I will employ live phone interviews using Random Digit Dialing (RDD) and SMS text polls, ensuring coverage of both landline and mobile users.
In-Person Recruitment: In key battleground states, local fieldworkers will be deployed to recruit voters who may not be reached through digital or phone methods, ensuring a geographically diverse sample.
3. Data Validation and Quality Control
Data quality is crucial for accurate forecasting, and several measures will be implemented to ensure the validity of responses:\
Voter Verification: Respondents will be asked to confirm their voter registration status, and a subset of the sample will be cross-checked with voter databases to validate their responses.
Attention Checks: To minimize random or disengaged responses, I will include attention checks (e.g., questions asking respondents to select a specific answer) throughout the survey.
Duplicate Prevention: Respondent IP addresses and email addresses will be tracked to prevent multiple submissions from the same individual.
Weighting: Post-stratification weighting will be applied to adjust for any demographic imbalances in the final sample. Weighting factors will be based on age, gender, race, education, and voting history to match U.S. population benchmarks.

4. Poll Aggregation and Forecasting Model
In addition to my own survey, I will aggregate data from other reputable pollsters to improve the accuracy of the forecast.

Poll Aggregation: I will collect data from publicly available polls (e.g., FiveThirtyEight, RealClearPolitics) and develop a weighted average based on the reliability of each poll, sample size, and recency.
Weighting by Pollster Quality: Pollsters will be rated based on their historical accuracy, sample sizes, and transparency in methodology. More reliable polls will be weighted higher in the aggregation model.
Predictive Modeling: I will use a Bayesian predictive model that incorporates current polling data, historical voting patterns, economic indicators, and other key variables to generate a probabilistic forecast of the election outcome.

5. Questionnaire Design
The survey will be structured to capture key insights into voting intention, candidate favorability, and the issues driving voter decisions. It will be short and simple, taking no more than 10 minutes to complete.
Survey Link
The survey has been implemented using Google Forms. Here is the link to access the survey:\
https://forms.gle/BAZhkWDyLxAibwvu5

Budget Breakdown
Here is a proposed allocation of the $100,000 budget:\
Survey Platform and Software Costs: $5,000 for survey hosting on Google Forms and Qualtrics.
Recruitment Costs: $40,000 for online panel recruitment, social media ads, and targeted outreach.
Phone and SMS Polling: $20,000 to cover live phone interviews and SMS polling.
Fieldwork in Key States: $15,000 for in-person recruitment in battleground states.
Data Validation and Cleaning: $10,000 for voter verification, attention checks, and cleaning services.
Poll Aggregation and Modeling Tools: $7,000 for the development of a poll aggregation tool and Bayesian forecasting model.
Miscellaneous Costs: $3,000 for administrative costs, project management, and reporting.

\newpage


# References


