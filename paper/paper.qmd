---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - First author
  - Another author
thanks: "Code and data are available at: [https://github.com/RohanAlexander/starter_folder](https://github.com/RohanAlexander/starter_folder)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```


# Introduction

Election forecasting has long played a crucial role in understanding public opinion and predicting the outcome of political contests. The use of data-driven methods, particularly polling data, has become an important pre-election analytical tool for political analysts. The purpose of this paper is to predict the winner of the upcoming 2024 U.S. presidential election by constructing a statistical model based on aggregated polling data. The “polling” approach combines results from different pollsters to provide a more comprehensive picture of voter preferences (Blumenthal 2014; Pasek 2015), and our goal is to predict the outcome of the popular vote and the Electoral College. Our analysis, based on data collected from multiple polling sources, captures voter intentions for the two major candidates, Kamala Harris (Democrat) and Donald Trump (Republican).

In addition to constructing and interpreting predictive models, this paper dive into the methods used by xx pollsters, analyzing the strengths as well as the weaknesses of the methods used against them. At the end of the paper, we also propose an idealized survey methodology for election forecasting with a budget of $100,000 USD.

This paper begins with an introduction to data in Section 2. In this section, we focus on measurement techniques and the visualization and analysis of key variables. Next, in Section 3, we provide an overview of the linear model used to analyze the relationships within the dataset. The results of the analysis are detailed in Section 4 (Results). Finally, in Section 5, we summarize our main conclusions as well as suggest some possible future research directions.






# Data {#sec-data}

## Overview

The data for this paper was sourced from ABC News (xxxxx). The statistical software R (R Core Team, 2023) was employed to retrieve, clean, and process the dataset. Specifically, the tidyverse package (Wickham et al., 2019) was used for data acquisition, cleaning, and processing. The ggplot2 (Wickham, 2016) package was utilized to generate the visualizations.

## Measurement
	
The data used to predict the outcome of the 2024 U.S. presidential election in this study came from a variety of polling sources. The results of these polls represent key measures of electoral support and voter sentiment, and are therefore the main variables in our analysis.

To ensure that polling data accurately reflect real-world voter preferences, we rely on several key measurement constructs. First, voter preferences are measured by the percentage of respondents who indicated support for each candidate. Each poll is conducted using different sample sizes, sampling methods (e.g., online surveys, IVR calls, etc.), which can inject more variability into the data. To mitigate these differences, we aggregate poll results using a “”poll of polls“” methodology that eliminates anomalies and provides a more comprehensive picture of voter preferences (Blumenthal 2014; Pasek 2015).

In this study, we recognize the measurement problems inherent in polling data. Polls rely on sample data to represent the entire voting population, and therefore, there may be potential biases in the data. For example, there may be no-response bias due to the potential under representation of certain populations, or because of the wording of the questions and thus the influence of respondents to report their preferences. Therefore, in this study, we chose to analyze aggregated data from multiple pollsters and adjust for sampling variability and response rates in an effort to be able to provide a more robust measure of electoral support. We believe that our aggregated dataset can serve as a reliable basis for our predictive model to help us translate the data into quantitative metrics that can be used to predict election outcomes.


## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.



Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = "none") +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.








# Model

We performed multi-level regression with post-stratification (MRP) to predict support for Kamala Harris in the upcoming election. To perform MRP, we fit a logistic regression model to predict support for Harris using sex, age, race, race_hispanic, highest level of education, state, and urban as predictors on our survey data set [@americaspoliticalpulse], and post-stratified it using ACS census data [@citeIPUMS].

## Model set-up

We built our Bayesian logistic regression model using the `stan_glm()` function of the `rstanarm` package [@rstanarm]. The model that we use is:

\begin{align} 
vote\_harris_i|\pi_i &\sim \text{Bernoulli}(\pi_i) \\
\text{logit}(\pi_i) &= \beta_0 + \beta_1 \text{sex}_i + \beta_2  \text{age\_bracket}_i + \beta_3 \text{race}_i + \beta_4 \text{race\_hispanic}_i + \beta_5 \text{education\_level}_i + \beta_6 \text{urban}_i \\
\beta_0 &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5) \\
\beta_4 &\sim \text{Normal}(0, 2.5) \\
\beta_5 &\sim \text{Normal}(0, 2.5) \\
\beta_6 &\sim \text{Normal}(0, 2.5)
\end{align}

where binary variable $vote\_harris_i$ is equal to 1 if the respondent's preferred 2024 presidential candidate is Kamala Harris, or 0 if the respondent's preferred 2024 presidential candidate is Donald Trump. We run our model in R [@citeR] using `stan_glm`, with the default priors from `rstanarm` [@citerstanarm]. We then apply our model to our post-stratification data [@citeIPUMS] to predict the popular vote and electoral college results of the 2024 U.S. Presidential election.

Our model uses logistic regression, therefore one of its weaknesses is the fact that it predicts a binary outcome and does not consider the possibility that some American adults might vote for a third-party candidate or abstain from voting. Tradeoffs and concerns about our model are discussed in more detail in @sec-weaknesses-limitations.

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.


### Model justification

We expect a positive relationship between certain demographic characteristics and support for Kamala Harris. Specifically:

- **Sex**: We might expect differences in support between male and female respondents, with women potentially being more likely to support Kamala Harris due to certain policy stances that may appeal to this demographic.
- **Age Bracket**: Age can be a significant factor, as younger voters might lean more progressive, potentially increasing support for Kamala Harris compared to Donald Trump.
- **Race and Hispanic Ethnicity**: Historical voting patterns suggest that non-white racial groups, including Hispanic voters, may show stronger support for Democratic candidates, such as Harris. This is reflected in the coefficients $\beta_3$ for race and $\beta_4$ for Hispanic ethnicity.
- **Education Level**: Higher education levels are often correlated with progressive political views, so we might expect a positive relationship between education level and support for Harris.
- **Urban**: Respondents living in urban areas may be more likely to support Kamala Harris due to the urban-rural political divide observed in recent elections, where urban areas tend to lean more Democratic.

The coefficients, such as $\beta_1$ for sex and $\beta_2$ for age bracket, represent the strength of these relationships. For example, a positive value of $\beta_1$ would suggest that being female increases the probability of supporting Harris, all else being equal.

By using normal priors like $\beta_1 \sim \text{Normal}(0, 2.5)$, we assume that, before seeing the data, the effect of each predictor on the log-odds of supporting Kamala Harris is centered around zero, but with flexibility for the data to inform the posterior estimates.

The Bayesian framework allows us to capture the uncertainty in our estimates and to refine our understanding of how different factors influence political support as new data becomes available. This is especially important in political forecasting, where the relationships between demographic factors and candidate support can be influenced by evolving social and political dynamics.



# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```


# Appendix
## Emerson College Polling Methodology
For this deep dive, I'll focus on Emerson College Polling based on the link: Emerson College Polling - October 2024 National Poll.
Survey Overview:
The Emerson College Polling conducted a national survey in October 2024 to assess voter preferences for the upcoming U.S. presidential election. This appendix provides an in-depth analysis of their polling methodology, including the population, sample frame, recruitment process, and key strengths and weaknesses of their approach.

Methodology
1. Population, Frame, and Sample:\
Target Population: The target population for this poll includes U.S. citizens who are eligible to vote in the 2024 presidential election.
Sample Frame: The sample consists of likely voters across the United States. Emerson College Polling uses voter registration databases to develop a sampling frame of registered voters, ensuring they capture individuals who are most likely to vote in the upcoming election.
Sample Size: For this particular poll, 1,000 likely voters were surveyed. This sample size provides a margin of error of approximately ±3 percentage points, allowing for reasonable confidence in the poll's accuracy.

2. Sample Recruitment:\
Recruitment Method: Emerson College employs a multi-mode recruitment approach, including online, phone (landline and mobile), and SMS text outreach.
Phone Interviews: Live interviewers call both landlines and mobile phones using random digit dialing (RDD) to ensure they capture respondents without internet access.
Online Panels: Emerson also recruits respondents through online panels, using email invitations to individuals who match their demographic quotas.
SMS Text Polling: In recent years, Emerson has increasingly used SMS text polling, allowing respondents to complete the survey via mobile devices.

Trade-offs of Recruitment Method:\
Strengths: The multi-mode approach ensures better coverage of different demographic groups, including older adults and those less likely to engage with online surveys.
Weaknesses: The RDD approach can lead to lower response rates, especially with the increasing number of people avoiding unsolicited calls. The online component also introduces self-selection bias, where more politically engaged individuals may be overrepresented.

3. Sampling Approach and Trade-offs:\
Quota-based Sampling: Emerson uses quota sampling to ensure that the sample is representative of key demographics, including age, gender, race, and region. The quotas are based on U.S. Census data to maintain demographic diversity.
Weighting: After data collection, Emerson applies post-stratification weighting to adjust for any imbalances in the sample, aligning it with population benchmarks.
Trade-offs: While quota sampling ensures demographic diversity, it can introduce bias if certain groups are harder to reach or more likely to refuse participation (non-response bias). Weighting helps mitigate this issue but relies on accurate population benchmarks, which may not always reflect the electorate’s behavior accurately.

4. Non-response Handling:\
Non-response Bias: To minimize non-response bias, Emerson College Polling uses a combination of call-backs and reminder emails for online respondents. Additionally, post-survey weighting accounts for non-response patterns across key demographic groups.
Adjustments for Non-response: Emerson uses statistical weighting to adjust the final results based on the response rate within each demographic group (e.g., age, gender, and race). This helps to reduce the skew in the data caused by differential response rates.

5. Questionnaire Design:\
Strengths:
The survey is concise, focusing on core topics like voter intention, candidate preference, and key issues such as the economy and healthcare. This increases the likelihood that respondents complete the survey accurately and without fatigue.
Emerson regularly tests its questionnaire to ensure clarity and avoid ambiguous questions, improving the reliability of the responses.
Weaknesses:
Binary Choice Bias: Some sections of the questionnaire force a binary choice between two candidates, which may oversimplify the respondents' true preferences, especially in a race with multiple candidates or undecided voters.
Social Desirability Bias: Like most political polls, respondents may answer questions in a way they believe is socially acceptable, especially in terms of voter turnout or support for controversial candidates. This could lead to over-reporting of voter intention.
Summary of Strengths and Weaknesses
Strengths:

Multi-mode Surveying: Emerson’s use of phone, online, and SMS recruitment allows them to reach a broader cross-section of the population, minimizing the biases introduced by any one method.
Post-stratification Weighting: The weighting process ensures the sample reflects the U.S. population, improving the reliability of the poll results.
Timely Polling: The frequent release of polling data makes it possible to track shifts in voter sentiment over time.
Weaknesses:

Potential for Non-response Bias: Despite efforts to mitigate it, non-response remains a concern, particularly among certain voter demographics who may be harder to reach through phone or online surveys.
Self-selection Bias in Online Surveys: The online component may disproportionately attract respondents who are more politically engaged, which could skew results.
By employing a multi-mode approach and adjusting for demographic imbalances through weighting, Emerson College Polling provides robust and timely data. However, like all polls, it is subject to limitations, particularly around non-response and self-selection biases​
\newpage


# References


